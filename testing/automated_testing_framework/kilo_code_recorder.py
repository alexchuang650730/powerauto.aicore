#!/usr/bin/env python3
"""
Kilo Codeæ™ºèƒ½ä»‹å…¥æ£€æµ‹ä¸“ç”¨å½•åˆ¶å™¨

ä¸“é—¨ç”¨äºå½•åˆ¶å’ŒéªŒè¯Kilo Codeå¼•æ“çš„7ç§æŒ£æ‰æ¨¡å¼æ£€æµ‹ã€æ™ºèƒ½ä»‹å…¥å†³ç­–ç­‰åŠŸèƒ½
æ”¯æŒä¼ä¸šç‰ˆå’Œä¸ªäººä¸“ä¸šç‰ˆçš„ä¸åŒæµ‹è¯•åœºæ™¯
"""

import os
import sys
import json
import time
import asyncio
from pathlib import Path
from datetime import datetime
from typing import Dict, List, Any, Optional, Callable
from dataclasses import dataclass, asdict
from enum import Enum

# å¯¼å…¥é›†æˆçš„å½•åˆ¶å™¨
sys.path.append(str(Path(__file__).parent))
from workflow_recorder_integration import WorkflowRecorder, WorkflowRecordingConfig, KiloCodeDetectionEvent

class StruggleModeType(Enum):
    """7ç§æŒ£æ‰æ¨¡å¼ç±»å‹"""
    SYNTAX_ERROR = "struggle_mode_1"  # è¯­æ³•é”™è¯¯æŒ£æ‰
    LOGIC_ERROR = "struggle_mode_2"   # é€»è¾‘é”™è¯¯æŒ£æ‰
    PERFORMANCE_ISSUE = "struggle_mode_3"  # æ€§èƒ½é—®é¢˜æŒ£æ‰
    API_CONFUSION = "struggle_mode_4"  # APIä½¿ç”¨å›°æƒ‘
    DESIGN_PATTERN = "struggle_mode_5"  # è®¾è®¡æ¨¡å¼æŒ£æ‰
    DEBUGGING_STUCK = "struggle_mode_6"  # è°ƒè¯•å¡ä½
    TESTING_DIFFICULTY = "struggle_mode_7"  # æµ‹è¯•å›°éš¾

class InterventionType(Enum):
    """ä»‹å…¥ç±»å‹"""
    CODE_SUGGESTION = "code_suggestion"  # ä»£ç å»ºè®®
    ERROR_FIX = "error_fix"  # é”™è¯¯ä¿®å¤
    REFACTOR_ADVICE = "refactor_advice"  # é‡æ„å»ºè®®
    PERFORMANCE_TIP = "performance_tip"  # æ€§èƒ½æç¤º
    BEST_PRACTICE = "best_practice"  # æœ€ä½³å®è·µ
    DOCUMENTATION = "documentation"  # æ–‡æ¡£å¼•å¯¼
    TESTING_GUIDE = "testing_guide"  # æµ‹è¯•æŒ‡å¯¼

@dataclass
class KiloCodeTestScenario:
    """Kilo Codeæµ‹è¯•åœºæ™¯"""
    scenario_id: str
    scenario_name: str
    target_version: str  # enterprise, personal_pro
    struggle_modes: List[StruggleModeType]
    expected_interventions: List[InterventionType]
    performance_requirements: Dict[str, float]  # response_time, accuracy_rate
    test_data: Dict[str, Any]

class KiloCodeRecorder:
    """Kilo Codeä¸“ç”¨å½•åˆ¶å™¨"""
    
    def __init__(self, test_framework_dir: str = None):
        # åˆå§‹åŒ–åŸºç¡€å½•åˆ¶å™¨
        self.workflow_recorder = WorkflowRecorder(test_framework_dir)
        
        # Kilo Codeä¸“ç”¨ç›®å½•
        self.kilo_code_dir = self.workflow_recorder.recording_dir / "kilo_code_specialized"
        self.scenarios_dir = self.kilo_code_dir / "scenarios"
        self.results_dir = self.kilo_code_dir / "results"
        self.templates_dir = self.kilo_code_dir / "templates"
        
        for directory in [self.kilo_code_dir, self.scenarios_dir, self.results_dir, self.templates_dir]:
            directory.mkdir(parents=True, exist_ok=True)
        
        # é¢„å®šä¹‰æµ‹è¯•åœºæ™¯
        self.test_scenarios = self._load_predefined_scenarios()
        
        # å½“å‰å½•åˆ¶çŠ¶æ€
        self.current_scenario: Optional[KiloCodeTestScenario] = None
        self.current_recording_id: Optional[str] = None
        self.detected_struggle_modes: List[str] = []
        self.triggered_interventions: List[str] = []
        
        # æ€§èƒ½ç›‘æ§
        self.performance_metrics = {
            "response_times": [],
            "accuracy_scores": [],
            "intervention_success_rate": 0.0
        }
    
    def _load_predefined_scenarios(self) -> Dict[str, KiloCodeTestScenario]:
        """åŠ è½½é¢„å®šä¹‰æµ‹è¯•åœºæ™¯"""
        scenarios = {}
        
        # ä¼ä¸šç‰ˆåœºæ™¯
        scenarios["enterprise_full_detection"] = KiloCodeTestScenario(
            scenario_id="enterprise_full_detection",
            scenario_name="ä¼ä¸šç‰ˆå®Œæ•´æ£€æµ‹æµ‹è¯•",
            target_version="enterprise",
            struggle_modes=[mode for mode in StruggleModeType],
            expected_interventions=[intervention for intervention in InterventionType],
            performance_requirements={
                "max_response_time": 3.0,
                "min_accuracy_rate": 0.85,
                "min_intervention_success_rate": 0.80
            },
            test_data={
                "code_complexity": "high",
                "team_size": "large",
                "project_type": "enterprise_application"
            }
        )
        
        scenarios["enterprise_critical_modes"] = KiloCodeTestScenario(
            scenario_id="enterprise_critical_modes",
            scenario_name="ä¼ä¸šç‰ˆå…³é”®æ¨¡å¼æµ‹è¯•",
            target_version="enterprise",
            struggle_modes=[
                StruggleModeType.SYNTAX_ERROR,
                StruggleModeType.LOGIC_ERROR,
                StruggleModeType.PERFORMANCE_ISSUE
            ],
            expected_interventions=[
                InterventionType.CODE_SUGGESTION,
                InterventionType.ERROR_FIX,
                InterventionType.PERFORMANCE_TIP
            ],
            performance_requirements={
                "max_response_time": 2.5,
                "min_accuracy_rate": 0.90,
                "min_intervention_success_rate": 0.85
            },
            test_data={
                "priority": "critical",
                "environment": "production"
            }
        )
        
        # ä¸ªäººä¸“ä¸šç‰ˆåœºæ™¯
        scenarios["personal_pro_basic"] = KiloCodeTestScenario(
            scenario_id="personal_pro_basic",
            scenario_name="ä¸ªäººä¸“ä¸šç‰ˆåŸºç¡€æµ‹è¯•",
            target_version="personal_pro",
            struggle_modes=[
                StruggleModeType.SYNTAX_ERROR,
                StruggleModeType.API_CONFUSION,
                StruggleModeType.DEBUGGING_STUCK
            ],
            expected_interventions=[
                InterventionType.CODE_SUGGESTION,
                InterventionType.DOCUMENTATION,
                InterventionType.BEST_PRACTICE
            ],
            performance_requirements={
                "max_response_time": 3.5,
                "min_accuracy_rate": 0.80,
                "min_intervention_success_rate": 0.75
            },
            test_data={
                "user_level": "intermediate",
                "project_type": "personal_project"
            }
        )
        
        scenarios["personal_pro_learning"] = KiloCodeTestScenario(
            scenario_id="personal_pro_learning",
            scenario_name="ä¸ªäººä¸“ä¸šç‰ˆå­¦ä¹ åœºæ™¯",
            target_version="personal_pro",
            struggle_modes=[
                StruggleModeType.DESIGN_PATTERN,
                StruggleModeType.TESTING_DIFFICULTY
            ],
            expected_interventions=[
                InterventionType.BEST_PRACTICE,
                InterventionType.TESTING_GUIDE,
                InterventionType.DOCUMENTATION
            ],
            performance_requirements={
                "max_response_time": 4.0,
                "min_accuracy_rate": 0.75,
                "min_intervention_success_rate": 0.70
            },
            test_data={
                "user_level": "beginner",
                "learning_focus": "best_practices"
            }
        )
        
        return scenarios
    
    def start_scenario_recording(self, scenario_id: str, custom_config: Dict[str, Any] = None) -> str:
        """å¼€å§‹åœºæ™¯å½•åˆ¶"""
        if scenario_id not in self.test_scenarios:
            raise ValueError(f"æœªçŸ¥çš„æµ‹è¯•åœºæ™¯: {scenario_id}")
        
        self.current_scenario = self.test_scenarios[scenario_id]
        
        # é…ç½®å½•åˆ¶å‚æ•°
        config = WorkflowRecordingConfig(
            recording_mode="kilo_code_detection",
            target_version=self.current_scenario.target_version,
            enable_visual_verification=True,
            enable_screenshot=True,
            auto_generate_n8n=True,
            recording_quality="high"
        )
        
        # åº”ç”¨è‡ªå®šä¹‰é…ç½®
        if custom_config:
            for key, value in custom_config.items():
                if hasattr(config, key):
                    setattr(config, key, value)
        
        # å¼€å§‹å½•åˆ¶
        self.current_recording_id = self.workflow_recorder.start_recording(
            recording_name=f"KiloCode_{self.current_scenario.scenario_name}",
            config=config,
            description=f"Kilo Codeåœºæ™¯æµ‹è¯•: {self.current_scenario.scenario_name}"
        )
        
        # é‡ç½®çŠ¶æ€
        self.detected_struggle_modes = []
        self.triggered_interventions = []
        self.performance_metrics = {
            "response_times": [],
            "accuracy_scores": [],
            "intervention_success_rate": 0.0
        }
        
        print(f"ğŸ¬ å¼€å§‹Kilo Codeåœºæ™¯å½•åˆ¶: {self.current_scenario.scenario_name}")
        print(f"   åœºæ™¯ID: {scenario_id}")
        print(f"   ç›®æ ‡ç‰ˆæœ¬: {self.current_scenario.target_version}")
        print(f"   é¢„æœŸæŒ£æ‰æ¨¡å¼: {len(self.current_scenario.struggle_modes)} ç§")
        print(f"   é¢„æœŸä»‹å…¥ç±»å‹: {len(self.current_scenario.expected_interventions)} ç§")
        
        return self.current_recording_id
    
    def record_struggle_mode_detection(self, struggle_mode: StruggleModeType, 
                                     detection_data: Dict[str, Any],
                                     confidence_score: float,
                                     response_time: float) -> str:
        """å½•åˆ¶æŒ£æ‰æ¨¡å¼æ£€æµ‹"""
        if not self.current_recording_id:
            raise RuntimeError("æ²¡æœ‰æ´»è·ƒçš„å½•åˆ¶ä¼šè¯")
        
        # è®°å½•æ£€æµ‹äº‹ä»¶
        event_id = self.workflow_recorder.record_kilo_code_detection(
            detection_type=struggle_mode.value,
            detection_data=detection_data,
            confidence_score=confidence_score,
            response_time=response_time
        )
        
        # æ›´æ–°çŠ¶æ€
        self.detected_struggle_modes.append(struggle_mode.value)
        self.performance_metrics["response_times"].append(response_time)
        self.performance_metrics["accuracy_scores"].append(confidence_score)
        
        # éªŒè¯æ€§èƒ½è¦æ±‚
        self._validate_performance_requirements(response_time, confidence_score)
        
        print(f"ğŸ“ æ£€æµ‹åˆ°æŒ£æ‰æ¨¡å¼: {struggle_mode.name} (ç½®ä¿¡åº¦: {confidence_score:.2f}, å“åº”æ—¶é—´: {response_time:.2f}s)")
        
        return event_id
    
    def record_intervention_trigger(self, intervention_type: InterventionType,
                                  intervention_data: Dict[str, Any],
                                  success_rate: float,
                                  response_time: float) -> str:
        """å½•åˆ¶æ™ºèƒ½ä»‹å…¥è§¦å‘"""
        if not self.current_recording_id:
            raise RuntimeError("æ²¡æœ‰æ´»è·ƒçš„å½•åˆ¶ä¼šè¯")
        
        # è®°å½•ä»‹å…¥äº‹ä»¶
        event_id = self.workflow_recorder.record_kilo_code_detection(
            detection_type="intervention_trigger",
            detection_data={
                "intervention_type": intervention_type.value,
                "intervention_data": intervention_data,
                "success_rate": success_rate
            },
            confidence_score=success_rate,
            response_time=response_time
        )
        
        # æ›´æ–°çŠ¶æ€
        self.triggered_interventions.append(intervention_type.value)
        self.performance_metrics["response_times"].append(response_time)
        
        print(f"ğŸ¤– è§¦å‘æ™ºèƒ½ä»‹å…¥: {intervention_type.name} (æˆåŠŸç‡: {success_rate:.2f}, å“åº”æ—¶é—´: {response_time:.2f}s)")
        
        return event_id
    
    def record_accuracy_validation(self, validation_data: Dict[str, Any]) -> str:
        """å½•åˆ¶å‡†ç¡®ç‡éªŒè¯"""
        if not self.current_recording_id:
            raise RuntimeError("æ²¡æœ‰æ´»è·ƒçš„å½•åˆ¶ä¼šè¯")
        
        # è®¡ç®—æ•´ä½“å‡†ç¡®ç‡
        overall_accuracy = self._calculate_overall_accuracy(validation_data)
        
        # è®°å½•éªŒè¯äº‹ä»¶
        event_id = self.workflow_recorder.record_kilo_code_detection(
            detection_type="accuracy_validation",
            detection_data=validation_data,
            confidence_score=overall_accuracy,
            response_time=0.1  # éªŒè¯é€šå¸¸å¾ˆå¿«
        )
        
        print(f"âœ… å‡†ç¡®ç‡éªŒè¯: {overall_accuracy:.2f}")
        
        return event_id
    
    def stop_scenario_recording(self) -> Dict[str, Any]:
        """åœæ­¢åœºæ™¯å½•åˆ¶å¹¶ç”Ÿæˆåˆ†ææŠ¥å‘Š"""
        if not self.current_recording_id:
            raise RuntimeError("æ²¡æœ‰æ´»è·ƒçš„å½•åˆ¶ä¼šè¯")
        
        # åœæ­¢åŸºç¡€å½•åˆ¶
        recording_result = self.workflow_recorder.stop_recording()
        
        # ç”Ÿæˆåœºæ™¯åˆ†ææŠ¥å‘Š
        scenario_report = self._generate_scenario_report(recording_result)
        
        # ä¿å­˜åœºæ™¯ç»“æœ
        self._save_scenario_result(scenario_report)
        
        print(f"ğŸ¬ åœºæ™¯å½•åˆ¶å®Œæˆ: {self.current_scenario.scenario_name}")
        print(f"   æ£€æµ‹åˆ°æŒ£æ‰æ¨¡å¼: {len(self.detected_struggle_modes)}/{len(self.current_scenario.struggle_modes)}")
        print(f"   è§¦å‘ä»‹å…¥: {len(self.triggered_interventions)}")
        print(f"   å¹³å‡å“åº”æ—¶é—´: {scenario_report['performance_analysis']['average_response_time']:.2f}s")
        print(f"   å¹³å‡å‡†ç¡®ç‡: {scenario_report['performance_analysis']['average_accuracy']:.2f}")
        
        # é‡ç½®çŠ¶æ€
        self.current_scenario = None
        self.current_recording_id = None
        
        return scenario_report
    
    def _validate_performance_requirements(self, response_time: float, confidence_score: float):
        """éªŒè¯æ€§èƒ½è¦æ±‚"""
        if not self.current_scenario:
            return
        
        requirements = self.current_scenario.performance_requirements
        
        # æ£€æŸ¥å“åº”æ—¶é—´
        if response_time > requirements.get("max_response_time", 3.0):
            print(f"âš ï¸ å“åº”æ—¶é—´è¶…æ ‡: {response_time:.2f}s > {requirements['max_response_time']}s")
        
        # æ£€æŸ¥å‡†ç¡®ç‡
        if confidence_score < requirements.get("min_accuracy_rate", 0.85):
            print(f"âš ï¸ å‡†ç¡®ç‡ä¸è¶³: {confidence_score:.2f} < {requirements['min_accuracy_rate']}")
    
    def _calculate_overall_accuracy(self, validation_data: Dict[str, Any]) -> float:
        """è®¡ç®—æ•´ä½“å‡†ç¡®ç‡"""
        if not self.performance_metrics["accuracy_scores"]:
            return 0.0
        
        return sum(self.performance_metrics["accuracy_scores"]) / len(self.performance_metrics["accuracy_scores"])
    
    def _generate_scenario_report(self, recording_result: Dict[str, Any]) -> Dict[str, Any]:
        """ç”Ÿæˆåœºæ™¯åˆ†ææŠ¥å‘Š"""
        if not self.current_scenario:
            return {}
        
        # æ€§èƒ½åˆ†æ
        performance_analysis = {
            "average_response_time": sum(self.performance_metrics["response_times"]) / len(self.performance_metrics["response_times"]) if self.performance_metrics["response_times"] else 0,
            "max_response_time": max(self.performance_metrics["response_times"]) if self.performance_metrics["response_times"] else 0,
            "min_response_time": min(self.performance_metrics["response_times"]) if self.performance_metrics["response_times"] else 0,
            "average_accuracy": sum(self.performance_metrics["accuracy_scores"]) / len(self.performance_metrics["accuracy_scores"]) if self.performance_metrics["accuracy_scores"] else 0,
            "response_time_compliance": sum(1 for rt in self.performance_metrics["response_times"] if rt <= self.current_scenario.performance_requirements.get("max_response_time", 3.0)) / len(self.performance_metrics["response_times"]) if self.performance_metrics["response_times"] else 0,
            "accuracy_compliance": sum(1 for acc in self.performance_metrics["accuracy_scores"] if acc >= self.current_scenario.performance_requirements.get("min_accuracy_rate", 0.85)) / len(self.performance_metrics["accuracy_scores"]) if self.performance_metrics["accuracy_scores"] else 0
        }
        
        # è¦†ç›–ç‡åˆ†æ
        coverage_analysis = {
            "struggle_mode_coverage": len(set(self.detected_struggle_modes)) / len(self.current_scenario.struggle_modes),
            "intervention_coverage": len(set(self.triggered_interventions)) / len(self.current_scenario.expected_interventions),
            "detected_struggle_modes": list(set(self.detected_struggle_modes)),
            "triggered_interventions": list(set(self.triggered_interventions)),
            "missing_struggle_modes": [mode.value for mode in self.current_scenario.struggle_modes if mode.value not in self.detected_struggle_modes],
            "missing_interventions": [intervention.value for intervention in self.current_scenario.expected_interventions if intervention.value not in self.triggered_interventions]
        }
        
        # è´¨é‡è¯„ä¼°
        quality_score = (
            performance_analysis["response_time_compliance"] * 0.3 +
            performance_analysis["accuracy_compliance"] * 0.4 +
            coverage_analysis["struggle_mode_coverage"] * 0.2 +
            coverage_analysis["intervention_coverage"] * 0.1
        )
        
        report = {
            "scenario_info": asdict(self.current_scenario),
            "recording_info": {
                "recording_id": self.current_recording_id,
                "start_time": recording_result.get("start_time"),
                "end_time": recording_result.get("end_time"),
                "duration": recording_result.get("statistics", {}).get("recording_duration", 0)
            },
            "performance_analysis": performance_analysis,
            "coverage_analysis": coverage_analysis,
            "quality_assessment": {
                "overall_quality_score": quality_score,
                "performance_grade": self._get_performance_grade(performance_analysis),
                "coverage_grade": self._get_coverage_grade(coverage_analysis),
                "recommendations": self._generate_recommendations(performance_analysis, coverage_analysis)
            },
            "raw_recording_data": recording_result
        }
        
        return report
    
    def _get_performance_grade(self, performance_analysis: Dict[str, Any]) -> str:
        """è·å–æ€§èƒ½ç­‰çº§"""
        compliance_avg = (performance_analysis["response_time_compliance"] + performance_analysis["accuracy_compliance"]) / 2
        
        if compliance_avg >= 0.95:
            return "A+"
        elif compliance_avg >= 0.90:
            return "A"
        elif compliance_avg >= 0.85:
            return "B+"
        elif compliance_avg >= 0.80:
            return "B"
        elif compliance_avg >= 0.70:
            return "C"
        else:
            return "D"
    
    def _get_coverage_grade(self, coverage_analysis: Dict[str, Any]) -> str:
        """è·å–è¦†ç›–ç‡ç­‰çº§"""
        coverage_avg = (coverage_analysis["struggle_mode_coverage"] + coverage_analysis["intervention_coverage"]) / 2
        
        if coverage_avg >= 0.95:
            return "A+"
        elif coverage_avg >= 0.90:
            return "A"
        elif coverage_avg >= 0.85:
            return "B+"
        elif coverage_avg >= 0.80:
            return "B"
        elif coverage_avg >= 0.70:
            return "C"
        else:
            return "D"
    
    def _generate_recommendations(self, performance_analysis: Dict[str, Any], 
                                coverage_analysis: Dict[str, Any]) -> List[str]:
        """ç”Ÿæˆæ”¹è¿›å»ºè®®"""
        recommendations = []
        
        # æ€§èƒ½å»ºè®®
        if performance_analysis["response_time_compliance"] < 0.85:
            recommendations.append("å»ºè®®ä¼˜åŒ–Kilo Codeå¼•æ“å“åº”æ—¶é—´ï¼Œå½“å‰å“åº”æ—¶é—´è¶…æ ‡ç‡è¾ƒé«˜")
        
        if performance_analysis["accuracy_compliance"] < 0.85:
            recommendations.append("å»ºè®®æå‡æ£€æµ‹å‡†ç¡®ç‡ï¼Œå½“å‰å‡†ç¡®ç‡æœªè¾¾åˆ°85%è¦æ±‚")
        
        # è¦†ç›–ç‡å»ºè®®
        if coverage_analysis["struggle_mode_coverage"] < 0.90:
            missing_modes = coverage_analysis["missing_struggle_modes"]
            recommendations.append(f"å»ºè®®å¢å¼ºä»¥ä¸‹æŒ£æ‰æ¨¡å¼çš„æ£€æµ‹èƒ½åŠ›: {', '.join(missing_modes)}")
        
        if coverage_analysis["intervention_coverage"] < 0.80:
            missing_interventions = coverage_analysis["missing_interventions"]
            recommendations.append(f"å»ºè®®å®Œå–„ä»¥ä¸‹ä»‹å…¥ç±»å‹çš„è§¦å‘æœºåˆ¶: {', '.join(missing_interventions)}")
        
        # ç‰ˆæœ¬ç‰¹å®šå»ºè®®
        if self.current_scenario and self.current_scenario.target_version == "enterprise":
            if performance_analysis["average_response_time"] > 2.0:
                recommendations.append("ä¼ä¸šç‰ˆåº”ä¼˜åŒ–åˆ°2ç§’å†…å“åº”ï¼Œä»¥æ»¡è¶³ä¼ä¸šçº§æ€§èƒ½è¦æ±‚")
        
        if not recommendations:
            recommendations.append("å½“å‰æµ‹è¯•è¡¨ç°è‰¯å¥½ï¼Œå»ºè®®ç»§ç»­ä¿æŒå¹¶å®šæœŸéªŒè¯")
        
        return recommendations
    
    def _save_scenario_result(self, scenario_report: Dict[str, Any]):
        """ä¿å­˜åœºæ™¯ç»“æœ"""
        if not self.current_scenario:
            return
        
        # è½¬æ¢æšä¸¾ç±»å‹ä¸ºå­—ç¬¦ä¸²ä»¥æ”¯æŒJSONåºåˆ—åŒ–
        def convert_enums(obj):
            if isinstance(obj, dict):
                return {k: convert_enums(v) for k, v in obj.items()}
            elif isinstance(obj, list):
                return [convert_enums(item) for item in obj]
            elif isinstance(obj, (StruggleModeType, InterventionType)):
                return obj.value
            else:
                return obj
        
        serializable_report = convert_enums(scenario_report)
        
        # ä¿å­˜è¯¦ç»†æŠ¥å‘Š
        report_path = self.results_dir / f"{self.current_scenario.scenario_id}_{self.current_recording_id}_report.json"
        with open(report_path, 'w', encoding='utf-8') as f:
            json.dump(serializable_report, f, indent=2, ensure_ascii=False)
        
        # ä¿å­˜ç®€åŒ–æ‘˜è¦
        summary = {
            "scenario_id": self.current_scenario.scenario_id,
            "recording_id": self.current_recording_id,
            "timestamp": datetime.now().isoformat(),
            "quality_score": scenario_report["quality_assessment"]["overall_quality_score"],
            "performance_grade": scenario_report["quality_assessment"]["performance_grade"],
            "coverage_grade": scenario_report["quality_assessment"]["coverage_grade"],
            "average_response_time": scenario_report["performance_analysis"]["average_response_time"],
            "average_accuracy": scenario_report["performance_analysis"]["average_accuracy"]
        }
        
        summary_path = self.results_dir / f"{self.current_scenario.scenario_id}_{self.current_recording_id}_summary.json"
        with open(summary_path, 'w', encoding='utf-8') as f:
            json.dump(summary, f, indent=2, ensure_ascii=False)
        
        print(f"ğŸ’¾ åœºæ™¯ç»“æœå·²ä¿å­˜:")
        print(f"   è¯¦ç»†æŠ¥å‘Š: {report_path}")
        print(f"   æ‘˜è¦: {summary_path}")
    
    def list_scenarios(self) -> List[Dict[str, Any]]:
        """åˆ—å‡ºæ‰€æœ‰å¯ç”¨åœºæ™¯"""
        scenarios = []
        for scenario_id, scenario in self.test_scenarios.items():
            scenarios.append({
                "scenario_id": scenario_id,
                "scenario_name": scenario.scenario_name,
                "target_version": scenario.target_version,
                "struggle_modes_count": len(scenario.struggle_modes),
                "expected_interventions_count": len(scenario.expected_interventions),
                "max_response_time": scenario.performance_requirements.get("max_response_time", 0),
                "min_accuracy_rate": scenario.performance_requirements.get("min_accuracy_rate", 0)
            })
        
        return scenarios
    
    def get_scenario_history(self, scenario_id: str) -> List[Dict[str, Any]]:
        """è·å–åœºæ™¯å†å²è®°å½•"""
        history = []
        
        for summary_file in self.results_dir.glob(f"{scenario_id}_*_summary.json"):
            try:
                with open(summary_file, 'r', encoding='utf-8') as f:
                    summary = json.load(f)
                    history.append(summary)
            except Exception as e:
                print(f"âš ï¸ è¯»å–å†å²è®°å½•å¤±è´¥ {summary_file}: {e}")
        
        return sorted(history, key=lambda x: x.get("timestamp", ""), reverse=True)

if __name__ == "__main__":
    # ç¤ºä¾‹ä½¿ç”¨
    kilo_recorder = KiloCodeRecorder()
    
    # åˆ—å‡ºå¯ç”¨åœºæ™¯
    scenarios = kilo_recorder.list_scenarios()
    print("ğŸ“‹ å¯ç”¨çš„Kilo Codeæµ‹è¯•åœºæ™¯:")
    for scenario in scenarios:
        print(f"   {scenario['scenario_id']}: {scenario['scenario_name']} ({scenario['target_version']})")
    
    # æ‰§è¡Œä¼ä¸šç‰ˆå…³é”®æ¨¡å¼æµ‹è¯•
    print(f"\nğŸ¬ å¼€å§‹æ‰§è¡Œä¼ä¸šç‰ˆå…³é”®æ¨¡å¼æµ‹è¯•...")
    
    recording_id = kilo_recorder.start_scenario_recording("enterprise_critical_modes")
    
    # æ¨¡æ‹ŸæŒ£æ‰æ¨¡å¼æ£€æµ‹
    kilo_recorder.record_struggle_mode_detection(
        struggle_mode=StruggleModeType.SYNTAX_ERROR,
        detection_data={"error_type": "missing_semicolon", "line": 42},
        confidence_score=0.95,
        response_time=1.2
    )
    
    kilo_recorder.record_struggle_mode_detection(
        struggle_mode=StruggleModeType.LOGIC_ERROR,
        detection_data={"error_type": "infinite_loop", "complexity": "medium"},
        confidence_score=0.88,
        response_time=2.1
    )
    
    kilo_recorder.record_struggle_mode_detection(
        struggle_mode=StruggleModeType.PERFORMANCE_ISSUE,
        detection_data={"issue_type": "memory_leak", "severity": "high"},
        confidence_score=0.92,
        response_time=1.8
    )
    
    # æ¨¡æ‹Ÿæ™ºèƒ½ä»‹å…¥
    kilo_recorder.record_intervention_trigger(
        intervention_type=InterventionType.CODE_SUGGESTION,
        intervention_data={"suggestion": "æ·»åŠ åˆ†å·", "confidence": 0.95},
        success_rate=0.90,
        response_time=0.8
    )
    
    kilo_recorder.record_intervention_trigger(
        intervention_type=InterventionType.ERROR_FIX,
        intervention_data={"fix_type": "loop_condition", "auto_fix": True},
        success_rate=0.85,
        response_time=1.5
    )
    
    # éªŒè¯å‡†ç¡®ç‡
    kilo_recorder.record_accuracy_validation({
        "total_detections": 3,
        "correct_detections": 3,
        "false_positives": 0,
        "false_negatives": 0
    })
    
    # åœæ­¢å½•åˆ¶å¹¶ç”ŸæˆæŠ¥å‘Š
    scenario_report = kilo_recorder.stop_scenario_recording()
    
    print(f"\nğŸ“Š åœºæ™¯æµ‹è¯•æŠ¥å‘Š:")
    print(f"   è´¨é‡è¯„åˆ†: {scenario_report['quality_assessment']['overall_quality_score']:.2f}")
    print(f"   æ€§èƒ½ç­‰çº§: {scenario_report['quality_assessment']['performance_grade']}")
    print(f"   è¦†ç›–ç‡ç­‰çº§: {scenario_report['quality_assessment']['coverage_grade']}")
    
    print(f"\nğŸ‰ Kilo Codeä¸“ç”¨å½•åˆ¶å™¨æ¼”ç¤ºå®Œæˆï¼")

